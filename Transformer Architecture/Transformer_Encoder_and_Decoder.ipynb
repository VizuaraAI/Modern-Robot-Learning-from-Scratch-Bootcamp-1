{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 1 — Setup (imports, seed, device)"
      ],
      "metadata": {
        "id": "xE7GzZBcbq0M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ah2kc6SX79D",
        "outputId": "84dbbcb3-410d-493a-a3f0-9f6b3d6a462b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import math, random, time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 2 — Create a toy “translation” task + vocabulary + encode/decode"
      ],
      "metadata": {
        "id": "cjmvmymdbtp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS  = [\"red\",\"blue\",\"green\",\"yellow\",\"black\",\"white\",\"orange\",\"purple\"]\n",
        "OBJECTS = [\"car\",\"bike\",\"house\",\"shirt\",\"phone\",\"book\",\"cup\",\"bag\"]\n",
        "SEP = \"and\"\n",
        "\n",
        "SPECIALS = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]\n",
        "PAD, BOS, EOS, UNK = SPECIALS\n",
        "\n",
        "def make_example(max_pairs=3):\n",
        "    n = random.randint(1, max_pairs)\n",
        "    pairs = [(random.choice(COLORS), random.choice(OBJECTS)) for _ in range(n)]\n",
        "\n",
        "    src_tokens, tgt_tokens = [], []\n",
        "    for i, (c, o) in enumerate(pairs):\n",
        "        if i > 0:\n",
        "            src_tokens.append(SEP)\n",
        "            tgt_tokens.append(SEP)\n",
        "        src_tokens += [c, o]\n",
        "        tgt_tokens += [o, c]\n",
        "    return src_tokens, tgt_tokens\n",
        "\n",
        "# Build vocab\n",
        "vocab_tokens = SPECIALS + sorted(set(COLORS + OBJECTS + [SEP]))\n",
        "stoi = {tok: i for i, tok in enumerate(vocab_tokens)}\n",
        "itos = {i: tok for tok, i in stoi.items()}\n",
        "\n",
        "pad_id = stoi[PAD]\n",
        "bos_id = stoi[BOS]\n",
        "eos_id = stoi[EOS]\n",
        "unk_id = stoi[UNK]\n",
        "\n",
        "def encode(tokens):\n",
        "    return [bos_id] + [stoi.get(t, unk_id) for t in tokens] + [eos_id]\n",
        "\n",
        "def decode(ids):\n",
        "    out = []\n",
        "    for i in ids:\n",
        "        tok = itos[int(i)]\n",
        "        if tok in (BOS, PAD):\n",
        "            continue\n",
        "        if tok == EOS:\n",
        "            break\n",
        "        out.append(tok)\n",
        "    return out\n",
        "\n",
        "# Quick sanity check\n",
        "src, tgt = make_example()\n",
        "print(\"SRC:\", \" \".join(src))\n",
        "print(\"TGT:\", \" \".join(tgt))\n",
        "print(\"Encoded SRC:\", encode(src))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qhu9VZbbyWO",
        "outputId": "d97b4749-ff30-4a0f-f90f-3a9716b33324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: blue car and black shirt and yellow house\n",
            "TGT: car blue and shirt black and house yellow\n",
            "Encoded SRC: [1, 8, 10, 4, 7, 18, 4, 20, 13, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 — Dataset + padding collate + DataLoaders"
      ],
      "metadata": {
        "id": "gz5PXkSDcERG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyTranslationDataset(Dataset):\n",
        "    def __init__(self, n_samples):\n",
        "        self.data = [make_example(max_pairs=3) for _ in range(n_samples)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_tokens, tgt_tokens = self.data[idx]\n",
        "        return (torch.tensor(encode(src_tokens), dtype=torch.long),\n",
        "                torch.tensor(encode(tgt_tokens), dtype=torch.long))\n",
        "\n",
        "def collate_batch(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    src_len = max(x.size(0) for x in src_batch)\n",
        "    tgt_len = max(x.size(0) for x in tgt_batch)\n",
        "\n",
        "    src_padded = torch.full((len(batch), src_len), pad_id, dtype=torch.long)\n",
        "    tgt_padded = torch.full((len(batch), tgt_len), pad_id, dtype=torch.long)\n",
        "\n",
        "    for i, (src, tgt) in enumerate(zip(src_batch, tgt_batch)):\n",
        "        src_padded[i, :src.size(0)] = src\n",
        "        tgt_padded[i, :tgt.size(0)] = tgt\n",
        "\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "train_ds = ToyTranslationDataset(n_samples=8000)\n",
        "val_ds   = ToyTranslationDataset(n_samples=1000)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True,  collate_fn=collate_batch)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=128, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "print(\"Vocab size:\", len(stoi))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjnmnsG3cEtd",
        "outputId": "21c29405-d0ea-47b6-c1c0-de151978fb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_3Rkkudap-",
        "outputId": "74cbc24e-f99b-4095-b5fc-006547045edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  8,  6,  4, 14, 10,  4, 17,  6,  2]),\n",
              " tensor([ 1,  6,  8,  4, 10, 14,  4,  6, 17,  2]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 4 — Define the Transformer Encoder–Decoder model"
      ],
      "metadata": {
        "id": "DE1JQH7scMRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def pad_mask(x):\n",
        "    # True where padding is present\n",
        "    return x.eq(pad_id)\n",
        "\n",
        "def subsequent_mask(sz, device):\n",
        "    # True means \"mask out\" future tokens (causal)\n",
        "    return torch.triu(torch.ones((sz, sz), device=device, dtype=torch.bool), diagonal=1)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=4, enc_layers=2, dec_layers=2, ff_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.tgt_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=enc_layers,\n",
        "            num_decoder_layers=dec_layers,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt_in):\n",
        "        src_key_padding_mask = pad_mask(src)\n",
        "        tgt_key_padding_mask = pad_mask(tgt_in)\n",
        "        tgt_mask = subsequent_mask(tgt_in.size(1), src.device)\n",
        "\n",
        "        src_e = self.pos_enc(self.src_emb(src) * math.sqrt(self.d_model))\n",
        "        tgt_e = self.pos_enc(self.tgt_emb(tgt_in) * math.sqrt(self.d_model))\n",
        "\n",
        "        h = self.transformer(\n",
        "            src_e, tgt_e,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            memory_key_padding_mask=src_key_padding_mask,\n",
        "        )\n",
        "        return self.out(h)  # (batch, tgt_len, vocab_size)\n",
        "\n",
        "model = Seq2SeqTransformer(vocab_size=len(stoi)).to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdh7jgo3cNCy",
        "outputId": "9e317e76-97aa-430a-f603-eef75a4f823e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2SeqTransformer(\n",
            "  (src_emb): Embedding(21, 128)\n",
            "  (tgt_emb): Embedding(21, 128)\n",
            "  (pos_enc): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-1): 2 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-1): 2 x TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (out): Linear(in_features=128, out_features=21, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 5 — Train (teacher forcing + loss + accuracy)"
      ],
      "metadata": {
        "id": "fYt55xDpcizO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def run_epoch(dl, training=True):\n",
        "    model.train(training)\n",
        "    total_loss, total_tokens, correct_tokens = 0.0, 0, 0\n",
        "\n",
        "    for src, tgt in dl:\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        tgt_in  = tgt[:, :-1]   # input to decoder\n",
        "        tgt_out = tgt[:, 1:]    # what we want to predict\n",
        "\n",
        "        logits = model(src, tgt_in)  # (B, T, V)\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "\n",
        "        if training:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = logits.argmax(dim=-1)\n",
        "        mask = tgt_out.ne(pad_id)\n",
        "        correct_tokens += (preds.eq(tgt_out) & mask).sum().item()\n",
        "        total_tokens += mask.sum().item()\n",
        "\n",
        "    return total_loss / len(dl), correct_tokens / max(1, total_tokens)\n",
        "\n",
        "EPOCHS = 25\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    t0 = time.time()\n",
        "    train_loss, train_acc = run_epoch(train_dl, training=True)\n",
        "    val_loss, val_acc     = run_epoch(val_dl,   training=False)\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss {train_loss:.3f}, acc {train_acc:.3f} | \"\n",
        "          f\"val loss {val_loss:.3f}, acc {val_acc:.3f} | {dt:.1f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXrxKSDackOI",
        "outputId": "d6516a2d-e48c-4077-fd20-fe3d642f1681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train loss 0.296, acc 0.870 | val loss 0.159, acc 0.938 | 16.7s\n",
            "Epoch 02 | train loss 0.262, acc 0.886 | val loss 0.148, acc 0.941 | 16.0s\n",
            "Epoch 03 | train loss 0.249, acc 0.890 | val loss 0.142, acc 0.944 | 16.7s\n",
            "Epoch 04 | train loss 0.240, acc 0.896 | val loss 0.124, acc 0.956 | 15.6s\n",
            "Epoch 05 | train loss 0.241, acc 0.895 | val loss 0.125, acc 0.954 | 16.6s\n",
            "Epoch 06 | train loss 0.229, acc 0.900 | val loss 0.116, acc 0.959 | 16.7s\n",
            "Epoch 07 | train loss 0.219, acc 0.907 | val loss 0.090, acc 0.979 | 15.8s\n",
            "Epoch 08 | train loss 0.207, acc 0.913 | val loss 0.080, acc 0.976 | 15.6s\n",
            "Epoch 09 | train loss 0.198, acc 0.917 | val loss 0.077, acc 0.973 | 15.8s\n",
            "Epoch 10 | train loss 0.188, acc 0.923 | val loss 0.057, acc 0.988 | 16.3s\n",
            "Epoch 11 | train loss 0.181, acc 0.926 | val loss 0.050, acc 0.986 | 15.6s\n",
            "Epoch 12 | train loss 0.166, acc 0.934 | val loss 0.064, acc 0.983 | 15.8s\n",
            "Epoch 13 | train loss 0.162, acc 0.936 | val loss 0.036, acc 0.993 | 16.1s\n",
            "Epoch 14 | train loss 0.150, acc 0.943 | val loss 0.029, acc 0.997 | 15.8s\n",
            "Epoch 15 | train loss 0.141, acc 0.946 | val loss 0.023, acc 0.996 | 15.6s\n",
            "Epoch 16 | train loss 0.135, acc 0.948 | val loss 0.021, acc 0.998 | 15.7s\n",
            "Epoch 17 | train loss 0.126, acc 0.953 | val loss 0.017, acc 0.997 | 16.5s\n",
            "Epoch 18 | train loss 0.122, acc 0.955 | val loss 0.011, acc 1.000 | 15.8s\n",
            "Epoch 19 | train loss 0.116, acc 0.958 | val loss 0.010, acc 0.999 | 15.6s\n",
            "Epoch 20 | train loss 0.102, acc 0.963 | val loss 0.013, acc 0.998 | 15.3s\n",
            "Epoch 21 | train loss 0.096, acc 0.966 | val loss 0.017, acc 0.996 | 16.1s\n",
            "Epoch 22 | train loss 0.085, acc 0.970 | val loss 0.009, acc 0.998 | 15.2s\n",
            "Epoch 23 | train loss 0.085, acc 0.970 | val loss 0.008, acc 0.999 | 15.4s\n",
            "Epoch 24 | train loss 0.083, acc 0.972 | val loss 0.004, acc 1.000 | 15.3s\n",
            "Epoch 25 | train loss 0.072, acc 0.975 | val loss 0.006, acc 1.000 | 16.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference (greedy decoding) + test examples"
      ],
      "metadata": {
        "id": "oFkBHvgMc2nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def greedy_decode(src_tokens, max_len=30):\n",
        "    model.eval()\n",
        "\n",
        "    src_ids = torch.tensor(encode(src_tokens), dtype=torch.long, device=device).unsqueeze(0)\n",
        "    src_pad = pad_mask(src_ids)\n",
        "\n",
        "    # Encoder -> memory\n",
        "    src_e = model.pos_enc(model.src_emb(src_ids) * math.sqrt(model.d_model))\n",
        "    memory = model.transformer.encoder(src_e, src_key_padding_mask=src_pad)\n",
        "\n",
        "    ys = torch.tensor([[bos_id]], dtype=torch.long, device=device)\n",
        "    for _ in range(max_len):\n",
        "        tgt_e = model.pos_enc(model.tgt_emb(ys) * math.sqrt(model.d_model))\n",
        "        tgt_m = subsequent_mask(ys.size(1), device=device)\n",
        "\n",
        "        out = model.transformer.decoder(\n",
        "            tgt_e, memory,\n",
        "            tgt_mask=tgt_m,\n",
        "            tgt_key_padding_mask=pad_mask(ys),\n",
        "            memory_key_padding_mask=src_pad\n",
        "        )\n",
        "        next_logits = model.out(out[:, -1, :])\n",
        "        next_id = int(next_logits.argmax(dim=-1).item())\n",
        "\n",
        "        ys = torch.cat([ys, torch.tensor([[next_id]], device=device)], dim=1)\n",
        "        if next_id == eos_id:\n",
        "            break\n",
        "\n",
        "    return decode(ys.squeeze(0))\n",
        "\n",
        "tests = [\n",
        "    [\"red\",\"car\"],\n",
        "    [\"blue\",\"bike\"],\n",
        "    [\"yellow\",\"book\",\"and\",\"black\",\"phone\"],\n",
        "    [\"white\",\"cup\",\"and\",\"orange\",\"shirt\",\"and\",\"green\",\"phone\"]\n",
        "]\n",
        "\n",
        "for s in tests:\n",
        "    pred = greedy_decode(s)\n",
        "    print(\"SRC:\", \" \".join(s))\n",
        "    print(\"PRD:\", \" \".join(pred))\n",
        "    print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNo--aQYc3Vm",
        "outputId": "9daf3471-73a7-42b0-bc61-f7f0e32a5581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: red car\n",
            "PRD: car red\n",
            "--------------------------------------------------\n",
            "SRC: blue bike\n",
            "PRD: bike blue\n",
            "--------------------------------------------------\n",
            "SRC: yellow book and black phone\n",
            "PRD: book yellow and phone black\n",
            "--------------------------------------------------\n",
            "SRC: white cup and orange shirt and green phone\n",
            "PRD: cup white and phone orange and shirt green\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}